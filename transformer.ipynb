{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Nov 10 18:13:27 2024\n",
    "\n",
    "@author: Jas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc264883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, LayerNormalization, Dropout, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac170b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love this movie', 'This was a great film', 'Fantastic story', 'Amazing movie', 'Really enjoyed it', 'I hated this movie', 'This movie was awful', 'Worst film ever', 'So boring', 'Not good at all']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a simple dataset of movie reviews\n",
    "reviews = [\n",
    "    \"I love this movie\", \"This was a great film\", \"Fantastic story\", \"Amazing movie\", \"Really enjoyed it\",\n",
    "    \"I hated this movie\", \"This movie was awful\", \"Worst film ever\", \"So boring\", \"Not good at all\"\n",
    "]\n",
    "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa5f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 6, 1, 2], [1, 4, 7, 8, 5], [9, 10], [11, 2], [12, 13, 14], [3, 15, 1, 2], [1, 2, 4, 16], [17, 5, 18], [19, 20], [21, 22, 23, 24]]\n",
      "[[ 3  6  1  2  0  0  0  0  0  0]\n",
      " [ 1  4  7  8  5  0  0  0  0  0]\n",
      " [ 9 10  0  0  0  0  0  0  0  0]\n",
      " [11  2  0  0  0  0  0  0  0  0]\n",
      " [12 13 14  0  0  0  0  0  0  0]\n",
      " [ 3 15  1  2  0  0  0  0  0  0]\n",
      " [ 1  2  4 16  0  0  0  0  0  0]\n",
      " [17  5 18  0  0  0  0  0  0  0]\n",
      " [19 20  0  0  0  0  0  0  0  0]\n",
      " [21 22 23 24  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "val=tokenizer.fit_on_texts(reviews)\n",
    "X = tokenizer.texts_to_sequences(reviews)\n",
    "print(X)\n",
    "# Step 3: Pad the sequences to make them the same length\n",
    "X = pad_sequences(X, padding='post', maxlen=10)\n",
    "print(X)\n",
    "# # Step 4: Create the Transformer model using Functional API\n",
    "embed_dim = 64  # Embedding dimension\n",
    "num_heads = 2   # Number of attention heads\n",
    "num_layers = 2  # Number of encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d33246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amang\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(10,))  # Input layer (sequence of integers)\n",
    "embedding_layer = Embedding(input_dim=1000, output_dim=embed_dim, input_length=10)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f94967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-3.41584906e-02  4.70875539e-02  4.98977341e-02 -3.08175571e-02\n",
      "   4.92170192e-02  4.63818796e-02 -3.05662286e-02 -7.57654756e-03\n",
      "  -2.26571914e-02 -3.33640203e-02 -2.32733022e-02 -1.10966340e-02\n",
      "   6.06539100e-03 -3.44159380e-02  3.67386267e-03 -1.57976747e-02\n",
      "   1.00117214e-02  3.68866362e-02 -3.12434193e-02 -3.93682607e-02\n",
      "  -4.85066064e-02 -3.58324125e-03 -1.52924657e-02  2.90969051e-02\n",
      "   2.29766704e-02  1.58852600e-02  1.54667608e-02  4.54081930e-02\n",
      "  -3.51678208e-03  4.16622795e-02  3.78173105e-02 -2.11986303e-02\n",
      "   3.11143883e-02  1.11247227e-03  3.24110501e-02 -3.70546803e-02\n",
      "  -1.55471936e-02 -4.52183969e-02 -2.91136391e-02 -2.55028605e-02\n",
      "  -4.15469632e-02  3.88257764e-02 -2.70545613e-02 -7.06039742e-03\n",
      "  -7.36974552e-03 -2.92605292e-02  3.23269404e-02  3.50591205e-02\n",
      "  -2.92478204e-02 -1.45514831e-02 -6.85628504e-03  1.63729228e-02\n",
      "   1.68222673e-02 -4.21718135e-02 -1.27538294e-03 -2.51648314e-02\n",
      "   2.41911411e-03 -1.81071870e-02  2.03178637e-02 -1.46273598e-02\n",
      "  -1.52966753e-02  4.57329676e-03  4.57607619e-02  3.25394161e-02]\n",
      " [ 7.23173469e-03 -3.81186977e-02  1.87315457e-02 -4.37994860e-02\n",
      "   3.27795260e-02 -4.93758805e-02 -4.97036092e-02  8.44386965e-03\n",
      "   2.17979066e-02 -2.24543214e-02 -4.32997607e-02 -2.95422077e-02\n",
      "  -1.15170479e-02  8.52330774e-03 -3.44576463e-02  1.50165893e-02\n",
      "   2.63029225e-02 -2.95781977e-02 -3.89959812e-02 -1.99056864e-02\n",
      "  -9.27654654e-03  8.51114839e-03 -3.46119776e-02 -4.48963754e-02\n",
      "  -4.13575880e-02  2.40742080e-02 -3.20767760e-02 -1.36188157e-02\n",
      "   1.08986124e-02 -1.09813437e-02 -2.38607414e-02  1.02604032e-02\n",
      "   3.82733382e-02  3.41648199e-02  1.57224648e-02  3.35186012e-02\n",
      "   1.22616999e-02  3.37787531e-02  1.96187161e-02  2.18384303e-02\n",
      "   1.29816681e-03 -3.57916467e-02  8.62874091e-04  3.53850611e-02\n",
      "   4.50544469e-02  8.14815611e-03  1.01884231e-02 -1.77220255e-03\n",
      "  -2.93902159e-02 -2.11856253e-02 -8.77361372e-03  2.85142325e-02\n",
      "  -1.29803792e-02  3.87973525e-02  2.68333815e-02  3.44240107e-02\n",
      "   2.31262185e-02  3.93929370e-02 -3.42898443e-03 -1.76666267e-02\n",
      "  -3.01786195e-02  3.60281207e-02 -4.01828401e-02  1.10951290e-02]\n",
      " [-2.99638752e-02 -3.11294943e-03  4.57889698e-02 -7.25520775e-03\n",
      "   4.39271964e-02 -4.13547158e-02 -7.48324394e-03 -3.83365974e-02\n",
      "  -2.46604811e-02 -3.13834436e-02 -1.56506784e-02 -4.59836610e-02\n",
      "  -2.99391150e-02  2.66901515e-02  4.83666323e-02  4.51042764e-02\n",
      "  -8.01984221e-03  1.74131058e-02  2.74045207e-02  4.14009951e-02\n",
      "   4.88915332e-02 -5.64293936e-03 -1.13292225e-02  3.98921110e-02\n",
      "   1.95044912e-02  1.35470517e-02 -4.22700532e-02 -2.39454750e-02\n",
      "  -7.19391182e-03 -3.53761911e-02 -3.65941599e-03 -2.39520911e-02\n",
      "   9.22659785e-03 -3.77208106e-02 -3.38851698e-02  4.41803969e-02\n",
      "   4.72995900e-02  1.76187195e-02  3.29347737e-02 -1.81349888e-02\n",
      "  -1.84603781e-03  4.08109464e-02 -1.52290575e-02  4.90438007e-02\n",
      "  -1.69063322e-02  4.17866819e-02 -4.82591987e-02  1.07540265e-02\n",
      "  -1.32003427e-02 -3.51558924e-02  3.77853028e-02  2.60840394e-02\n",
      "  -8.06616619e-03  7.37897307e-03  1.96084268e-02  3.31712477e-02\n",
      "   3.88415344e-02  2.09039561e-02  4.48427908e-02  8.12136009e-03\n",
      "  -3.27298269e-02 -3.82442586e-02 -2.68778205e-02 -1.98001154e-02]\n",
      " [ 2.56590135e-02  3.21058519e-02 -1.68508515e-02 -1.51179060e-02\n",
      "  -3.29808593e-02 -4.19684872e-02  2.32828893e-02 -1.59110315e-02\n",
      "  -3.50566730e-02  1.81061961e-02 -4.87157963e-02 -3.65460292e-02\n",
      "   1.13313422e-02 -4.31426540e-02 -4.08325307e-02 -3.28085572e-03\n",
      "   3.63460667e-02 -6.52233511e-03 -4.19253223e-02  1.97092928e-02\n",
      "  -3.15608270e-02  2.56085880e-02  4.88808006e-03 -1.45717375e-02\n",
      "   4.22117971e-02  2.11408772e-02 -2.28465721e-03  2.21821703e-02\n",
      "   5.80283254e-03  4.26505320e-02 -3.17617208e-02  2.38034241e-02\n",
      "   1.83875449e-02 -1.15944035e-02  3.90249602e-02 -3.72832194e-02\n",
      "  -5.64797968e-03 -4.48413007e-02  4.08088900e-02 -1.00586191e-02\n",
      "  -8.54283571e-03  2.77550854e-02  1.72145292e-03  8.73969868e-03\n",
      "  -3.50781083e-02  1.30590834e-02  4.93234284e-02  2.64922865e-02\n",
      "   3.01640108e-03  2.01913975e-02 -3.10799833e-02 -4.25113328e-02\n",
      "  -2.81200167e-02  3.61941755e-04 -2.89288294e-02  4.21165936e-02\n",
      "   4.83027138e-02  2.33900435e-02  4.49295752e-02  5.44019789e-03\n",
      "  -3.94051671e-02  1.57920755e-02 -8.56536627e-03  8.03492963e-04]\n",
      " [ 4.67158668e-02 -3.88603285e-03  1.54331811e-02 -8.20631906e-03\n",
      "  -7.29567930e-03 -1.08258836e-02  3.70993875e-02 -2.40395069e-02\n",
      "  -3.10984012e-02  3.12479995e-02 -4.34314124e-02 -1.29862800e-02\n",
      "  -9.23820585e-03  4.81506847e-02  5.56772947e-03 -2.12326180e-02\n",
      "   4.95719202e-02  3.59221362e-02 -1.75169595e-02  4.20640372e-02\n",
      "   1.95492394e-02 -2.03653108e-02  2.50833370e-02 -1.46984681e-02\n",
      "  -3.21781635e-03  1.46634690e-02  3.45204361e-02 -4.74788919e-02\n",
      "   2.02224962e-02  4.81549650e-03 -4.78558615e-03 -2.10351590e-02\n",
      "  -2.41642948e-02 -1.41786449e-02  3.25523727e-02  1.29162185e-02\n",
      "   1.95807330e-02 -1.47743113e-02  1.24750137e-02  2.38601230e-02\n",
      "  -3.16830873e-02 -3.11149713e-02 -9.61930677e-03 -2.88354997e-02\n",
      "  -3.88590321e-02 -3.53963152e-02  4.78292443e-02 -4.19428833e-02\n",
      "   7.40104914e-03  6.29089773e-04  3.96968983e-02 -1.04827173e-02\n",
      "   3.71657051e-02 -3.62262242e-02 -7.66766071e-03 -4.01808843e-02\n",
      "  -2.94567589e-02  8.90539959e-03 -2.00957302e-02 -3.45658138e-03\n",
      "  -4.26179171e-03 -3.27526331e-02  2.95234844e-03  4.75325100e-02]\n",
      " [-3.06876786e-02 -1.64601803e-02  1.03348605e-02 -4.14011255e-02\n",
      "   1.62151791e-02 -1.66884884e-02 -2.05271840e-02 -9.80205461e-03\n",
      "  -2.16046926e-02 -3.95441055e-03 -4.27663699e-02  3.08184065e-02\n",
      "   1.17457286e-02  2.15402991e-03 -2.62247566e-02  4.28253151e-02\n",
      "   2.02979110e-02  4.07305993e-02 -1.47539973e-02 -5.09021431e-03\n",
      "   1.43164434e-02 -2.40096692e-02 -2.31135637e-04  1.80819072e-02\n",
      "  -2.76731141e-02  2.88366787e-02 -4.12511118e-02 -1.40801296e-02\n",
      "  -3.10178157e-02 -9.79627296e-03  3.06232907e-02 -2.02752706e-02\n",
      "   2.66532041e-02  1.95825957e-02 -2.12550294e-02  3.93608920e-02\n",
      "  -4.82394099e-02 -7.32022524e-03 -4.37396057e-02  3.71443890e-02\n",
      "   4.52663414e-02  8.28224421e-03 -4.10586484e-02  4.81766127e-02\n",
      "  -2.48057730e-02  3.68139483e-02 -2.37275008e-02  3.34027521e-02\n",
      "  -3.72247770e-03  3.29729952e-02  2.53191851e-02  3.85180451e-02\n",
      "   2.82576121e-02  1.48192048e-05 -1.60763152e-02  4.21644337e-02\n",
      "  -2.72180792e-02  4.82811220e-02  4.83380444e-02  4.25359122e-02\n",
      "   1.08921751e-02 -1.42589808e-02  4.78554480e-02 -1.36684291e-02]\n",
      " [-1.85713992e-02 -3.06708738e-03  4.87248935e-02  6.37162849e-03\n",
      "  -4.43055294e-02  3.64822410e-02  4.63850833e-02  3.77344750e-02\n",
      "  -1.87021382e-02  2.95025371e-02  4.62647341e-02  8.47214460e-03\n",
      "   2.53064074e-02  3.48123796e-02  2.16747187e-02  1.01749413e-02\n",
      "   3.08873169e-02  2.72459276e-02 -2.90328395e-02  4.14933600e-02\n",
      "  -3.83952633e-02  2.85838358e-02  3.93823273e-02  3.14772166e-02\n",
      "   1.37826689e-02  1.29832141e-02 -4.55336943e-02 -3.16942818e-02\n",
      "  -3.50578874e-03  3.71956825e-03  8.68441910e-03 -8.09717178e-03\n",
      "  -2.45394241e-02 -4.50567491e-02  4.90936525e-02 -8.29195976e-03\n",
      "  -1.65453069e-02 -1.12437718e-02  1.57732703e-02  1.80474631e-02\n",
      "   1.88253075e-03  5.30732796e-03  3.27093340e-02  1.57924034e-02\n",
      "  -2.47399937e-02 -4.25621122e-03  2.84758247e-02  3.54621075e-02\n",
      "   1.50475986e-02  4.08427157e-02 -3.51674929e-02  2.47653238e-02\n",
      "  -4.79537733e-02  1.19748600e-02 -1.20246895e-02 -6.98759407e-03\n",
      "   4.10385244e-02  4.38430421e-02 -3.40765715e-02 -2.00876351e-02\n",
      "   2.19614841e-02 -2.37222202e-02  3.82523425e-02 -1.87541172e-03]\n",
      " [ 3.38591672e-02 -4.12831083e-02 -4.71619852e-02  2.70990282e-03\n",
      "   2.76503302e-02 -4.18054946e-02 -2.99765002e-02 -4.00176160e-02\n",
      "   3.37240957e-02 -4.95786592e-03 -3.68291363e-02 -4.64999452e-02\n",
      "  -4.17292118e-03 -3.39212306e-02 -1.76711194e-02  1.93452500e-02\n",
      "   3.04397829e-02  4.34890278e-02 -6.71712309e-03 -5.79056889e-03\n",
      "   1.82074197e-02 -1.92826632e-02  4.82150204e-02 -4.43784706e-02\n",
      "   2.50768103e-02 -3.04596499e-03  4.00425456e-02 -3.36846597e-02\n",
      "   5.19914553e-03 -1.71215646e-02 -8.69292021e-03  1.80704333e-02\n",
      "   3.89184393e-02 -3.86345983e-02 -1.25142224e-02  4.53949831e-02\n",
      "  -4.03867587e-02 -1.31957158e-02 -1.02525949e-02 -4.21017408e-02\n",
      "   1.41438283e-02 -1.73439272e-02  4.91940044e-02  2.71092989e-02\n",
      "   4.75442298e-02  4.93823402e-02 -3.41958292e-02  3.74404527e-02\n",
      "   2.29533948e-02  9.19627026e-03  2.45463587e-02 -9.06784460e-03\n",
      "   4.04354818e-02  3.00290324e-02 -1.99440867e-03  5.41207939e-03\n",
      "  -7.87622854e-03  3.03844847e-02 -1.08918771e-02 -4.35928814e-02\n",
      "  -1.20993964e-02 -2.67225746e-02  2.09640600e-02 -9.97855514e-03]\n",
      " [ 4.62782867e-02  1.72341578e-02 -4.47149873e-02 -4.58050370e-02\n",
      "  -1.74184330e-02 -4.86448668e-02  3.62928398e-02  1.17144212e-02\n",
      "   9.53762606e-03  1.83926485e-02 -2.52582319e-02 -4.45333384e-02\n",
      "  -4.46454994e-02  8.86639208e-03 -2.78975368e-02  1.68672912e-02\n",
      "  -2.90194638e-02 -4.34304588e-02  1.28816441e-03  3.23440917e-02\n",
      "  -1.84234269e-02  3.70148160e-02  2.02049948e-02  2.37920620e-02\n",
      "   2.42474116e-02  1.47505850e-03  1.76434629e-02 -2.12328508e-03\n",
      "   1.26077570e-02  3.33270691e-02 -1.96266063e-02  3.38214636e-03\n",
      "   4.30241860e-02 -1.58124045e-03 -5.62749058e-03 -3.56997028e-02\n",
      "  -2.49980818e-02  3.10196988e-02 -4.33970615e-03 -1.04930513e-02\n",
      "   3.36949490e-02  4.54773754e-03  3.34230997e-02 -3.47163193e-02\n",
      "   2.76773088e-02 -1.56977177e-02 -2.21923832e-02 -4.74844575e-02\n",
      "  -3.00655365e-02  3.87439243e-02 -3.60995643e-02  4.49766964e-03\n",
      "  -4.79030870e-02  6.44248724e-03 -1.97759755e-02  2.64850296e-02\n",
      "  -1.82615630e-02  3.88818495e-02 -1.23834610e-03  1.84679031e-03\n",
      "   1.69037692e-02  1.21051073e-02  4.91906144e-02  3.15072574e-02]\n",
      " [ 6.43754005e-03 -3.52074616e-02 -3.58896852e-02 -1.61592737e-02\n",
      "  -4.12771478e-02  4.54128273e-02  8.33685324e-03  2.00556591e-03\n",
      "  -4.59647067e-02 -2.42355000e-02  2.30183937e-02 -3.39226723e-02\n",
      "  -3.58622447e-02  2.18242668e-02 -1.20090470e-02  1.38818137e-02\n",
      "   5.62548637e-03 -6.17849827e-03 -2.25234628e-02  1.17599145e-02\n",
      "   3.32542099e-02  5.74479252e-03 -4.29873578e-02 -2.00707912e-02\n",
      "   3.97191681e-02 -4.22613509e-02 -1.25749223e-02 -1.42959245e-02\n",
      "  -3.80372405e-02 -1.72149539e-02  4.24124300e-04  2.34557427e-02\n",
      "   2.97483467e-02 -3.47711444e-02 -1.09301209e-02 -1.32608786e-02\n",
      "   1.99170373e-02  3.79597582e-02 -1.88242923e-02 -2.99240705e-02\n",
      "  -5.33999130e-03 -6.22313097e-03  1.53607987e-02  1.95500515e-02\n",
      "  -1.51368156e-02 -2.78540608e-02  3.04942392e-02 -3.56832892e-03\n",
      "   2.06204094e-02  4.11202647e-02 -2.81999465e-02  4.36182730e-02\n",
      "   9.87713411e-03  1.56223774e-03 -1.76236629e-02 -1.69846416e-02\n",
      "  -3.39003429e-02 -4.05509472e-02  4.80388142e-02 -3.05424221e-02\n",
      "   6.17364794e-03 -1.90185439e-02  1.15484111e-02 -4.34276350e-02]], shape=(10, 64), dtype=float32)\n",
      "<KerasTensor shape=(None, 10, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2>\n"
     ]
    }
   ],
   "source": [
    "# Positional Encoding: Adding simple positional encoding to the embeddings\n",
    "position_embedding = tf.keras.layers.Embedding(input_dim=10, output_dim=embed_dim)(tf.range(10))\n",
    "print(position_embedding)\n",
    "embedding_with_positional_encoding = embedding_layer + position_embedding\n",
    "print(embedding_with_positional_encoding)\n",
    "# Encoder layers using MultiHeadAttention\n",
    "x = embedding_with_positional_encoding  # Initial input to the Transformer encoder\n",
    "for _ in range(num_layers):\n",
    "      attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)  # Using self-attention\n",
    "      attention_output = LayerNormalization()(attention_output + x)  # Residual connection\n",
    "      attention_output = Dropout(0.1)(attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b924aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      # Feed Forward Network\n",
    "ff_output = Dense(64, activation='relu')(attention_output)\n",
    "ff_output = Dense(embed_dim)(ff_output)\n",
    "x = LayerNormalization()(ff_output + attention_output)  # Residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899279c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool the output (flatten and take the average over all tokens)\n",
    "x = GlobalAveragePooling1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82363141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final classification layer\n",
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7f4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e3a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37935945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.0000e+00 - loss: 0.7347\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.0000e+00 - loss: 0.6537\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0000e+00 - loss: 0.6821\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.0000e+00 - loss: 0.6280\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.0000e+00 - loss: 0.5769\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.0000e+00 - loss: 0.5844\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 0.5822   \n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step - accuracy: 0.0000e+00 - loss: 0.5761\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.0000e+00 - loss: 0.4980\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.0000e+00 - loss: 0.5042\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the model\n",
    "history = model.fit(X, labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5b4f6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.0\n",
      "Training loss: 0.4830702841281891\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X, labels, verbose=0)\n",
    "print(f'Training Accuracy: {train_accuracy}')\n",
    "print(f'Training loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739c4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Make a prediction with a new movie review\n",
    "test_review = [\"I really liked the movie\"]\n",
    "test_review_seq = tokenizer.texts_to_sequences(test_review)  # Tokenize the test review\n",
    "test_review_pad = pad_sequences(test_review_seq, padding='post', maxlen=10)  # Pad the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35b8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "Prediction for the new review: Positive\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_review_pad)  # Get the prediction\n",
    "print(f'Prediction for the new review: {\"Positive\" if prediction[0][0] > 0.5 else \"Negative\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e04e8-70c6-46f3-ab61-0a6e5aa54448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
